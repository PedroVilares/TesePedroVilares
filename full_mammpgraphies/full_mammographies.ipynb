{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy,pandas,os,sklearn,keras\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suspicious Mammographies (BCDR-D01 & BCDR-D02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdr1_raw = pd.read_csv('d:/BCDR/BCDR-D01_dataset/bcdr_d01_img.csv')\r\n",
    "bcdr1_raw = bcdr1_raw.drop_duplicates(subset=['image_filename'],keep='first',ignore_index=True)\r\n",
    "bcdr1_raw= utils.fix_view(bcdr1_raw,'image_type_name')\r\n",
    "bcdr1_features_raw = pd.read_csv('D:\\BCDR\\BCDR-D01_dataset/bcdr_d01_features.csv')\r\n",
    "bcdr2_raw = pd.read_csv('d:/BCDR/BCDR-D02_dataset/bcdr_d02_img.csv')\r\n",
    "bcdr2_raw = bcdr2_raw.drop_duplicates(subset=['image_filename'],keep='first',ignore_index=True)\r\n",
    "bcdr2_raw= utils.fix_view(bcdr2_raw,'image_type_name')\r\n",
    "bcdr2_features_raw = pd.read_csv('D:\\BCDR\\BCDR-D02_dataset/bcdr_d02_features.csv')\r\n",
    "l1 = utils.lesion_findings(bcdr1_features_raw)\r\n",
    "l2 = utils.lesion_findings(bcdr2_features_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdr1 = bcdr1_raw[['patient_id','study_id','image_filename','image_type_name','density','age']]\r\n",
    "bcdr1_features= bcdr1_features_raw[['patient_id','study_id','image_view','s_x_center_mass','s_y_center_mass','density','age']]\r\n",
    "\r\n",
    "bcdr1 = utils.merge_csv(bcdr1_features,bcdr1)\r\n",
    "bcdr1['lesion_type'] = l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdr2 = bcdr2_raw[['patient_id','study_id','image_filename','image_type_name','density','age']]\r\n",
    "bcdr2_features= bcdr2_features_raw[['patient_id','study_id','image_view','s_x_center_mass','s_y_center_mass','density','age']]\r\n",
    "\r\n",
    "bcdr2 = utils.merge_csv(bcdr2_features,bcdr2)\r\n",
    "bcdr2['lesion_type'] = l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_mammographies1 = pd.DataFrame({})\r\n",
    "lesion_mammographies1[['patient_id','image_view','image_path','x_center','y_center','density','age','lesion_type']] = bcdr1[['patient_id','image_view','image_filename','s_x_center_mass','s_y_center_mass','density','age','lesion_type']]\r\n",
    "new_patients = []\r\n",
    "for patient in list(lesion_mammographies1['patient_id']):\r\n",
    "    patient_n= '1d'+str(patient)\r\n",
    "    new_patients.append(patient_n)\r\n",
    "lesion_mammographies1['patient_id'] = new_patients\r\n",
    "lesion_mammographies1 = utils.fix_bcdr1_path(lesion_mammographies1,'image_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_mammographies2 = pd.DataFrame({})\r\n",
    "lesion_mammographies2[['patient_id','image_view','image_path','x_center','y_center','density','age','lesion_type']] = bcdr2[['patient_id','image_view','image_filename','s_x_center_mass','s_y_center_mass','density','age','lesion_type']]\r\n",
    "new_patients = []\r\n",
    "for patient in list(lesion_mammographies2['patient_id']):\r\n",
    "    patient_n= '2d'+str(patient)\r\n",
    "    new_patients.append(patient_n)\r\n",
    "lesion_mammographies2['patient_id'] = new_patients\r\n",
    "lesion_mammographies2 = utils.fix_bcdr2_path(lesion_mammographies2,'image_path')\r\n",
    "lesion_mammographies2 = lesion_mammographies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesion_mammographies = pd.concat([lesion_mammographies1,lesion_mammographies2],ignore_index=True)\r\n",
    "print('Suspicious Dataset: ',lesion_mammographies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sus_training,sus_validation = tts(lesion_mammographies,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.image_mover(sus_training,'image_data/raw/training/suspicious')\r\n",
    "utils.image_mover(sus_validation,'image_data/raw/validaiton/suspicious')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Mammographies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdrN = pd.read_csv('d:/BCDR/BCDR-DN01_dataset/bcdr_dn01_img.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_mammographies1 = pd.DataFrame({})\r\n",
    "normal_mammographies1[['patient_id','image_view','image_path','density','age']] = bcdrN[['patient_id','image_type_name','image_filename','density','age']]\r\n",
    "normal_mammographies1 = utils.fix_bcdrN_path(normal_mammographies1,'image_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_raw = pd.read_excel('D:/INBreast/INbreast.xls')\r\n",
    "xls = pd.DataFrame()\r\n",
    "xls['image_view'] = [xls_raw['Laterality'][i] + xls_raw['View'][i] for i in xls_raw.index] \r\n",
    "xls[['filename','finding notes']] = xls_raw[['File Name','Findings Notes (in Portuguese)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = os.listdir('D:/INBreast/AllDICOMs/')\r\n",
    "r = []\r\n",
    "for path in path_list:\r\n",
    "    if path[-3:] != 'dcm':\r\n",
    "        r.append(path)\r\n",
    "for i in r:\r\n",
    "    path_list.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = []\r\n",
    "file_paths = []\r\n",
    "image_views = []\r\n",
    "for path in path_list:\r\n",
    "    l = path.split('_')\r\n",
    "    if len(l) > 1:\r\n",
    "        patients.append(l[1])\r\n",
    "        file_paths.append(path)\r\n",
    "        image_views.append(l[3]+l[4])\r\n",
    "images_df = pd.DataFrame({'patient_id':patients,'image_view':image_views,'image_path':file_paths})\r\n",
    "images_df = utils.fix_inbreast_path(images_df,'image_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df[['finding notes']] = xls[['finding notes']]\r\n",
    "normal_df = images_df[images_df['finding notes'] == 'normal']\r\n",
    "normal_mammographies2 = pd.DataFrame()\r\n",
    "normal_mammographies2[['patient_id','image_view','image_path']] = normal_df[['patient_id','image_view','image_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_mammographies = pd.concat([normal_mammographies1,normal_mammographies2],ignore_index=True)\r\n",
    "print('Normal Dataset: ',normal_mammographies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_training,normal_validation = tts(normal_mammographies,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.image_mover(normal_training,'image_data/raw/training/normal')\r\n",
    "utils.image_mover(normal_validation,'image_data/raw/validaiton/normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Features Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.mammary_features('image_data/raw/training/normal/','features_training_normal.csv')\r\n",
    "utils.mammary_features('image_data/raw/training/suspicious/','features_training_suspicious.csv')\r\n",
    "utils.mammary_features('image_data/raw/validation/normal/','features_validation_normal.csv')\r\n",
    "utils.mammary_features('image_data/raw/validation/suspicious/','features_validation_suspicious.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Features Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Image Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Background and Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.downsample('image_data/raw/training/normal/','image_data/downsampled/train/normal/',1000,800)\r\n",
    "utils.downsample('image_data/raw/training/suspicious/','image_data/downsampled/train/suspicious/',1000,800)\r\n",
    "utils.downsample('image_data/raw/validation/normal/','image_data/downsampled/validation/normal/',1000,800)\r\n",
    "utils.downsample('image_data/raw/validation/suspicious/','image_data/downsampled/validation/suspicious/',1000,800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = True\r\n",
    "shuffle = True\r\n",
    "\r\n",
    "training_gen,validation_gen = utils.generator_transfer(1000,800,data_augmentation,shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.create_trans_model(1000,800)\r\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['binary_accuracy','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\r\n",
    "    training_gen,\r\n",
    "    epochs=25,\r\n",
    "    validation_data=validation_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bbe0d705c9fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'transfer.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('transfer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-08553f1fcf16>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-08553f1fcf16>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    y_true = validation_gen.\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "data = utils.generator_transfer(1000,800,True,False)\r\n",
    "y_true = data[1].classes\r\n",
    "y_pred = model.predict(data[1],data[1].samples//12+1)\r\n",
    "predictions_image = []\r\n",
    "for i in y_pred:\r\n",
    "    if i[0] > 0.5:\r\n",
    "        predictions_image.append(1)\r\n",
    "    else:\r\n",
    "        predictions_image.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sklearn.metris.confusion_matrix(y_true,predictions_image)\r\n",
    "sens = c[1][1]/(c[1][1]+c[1][0])\r\n",
    "spec = c[0][0]/(c[0][0]+c[0][1])\r\n",
    "print(c)\r\n",
    "print('Sensitivity:',sens)\r\n",
    "print('Specificity:',spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = sklearn.metrics.roc_auc_score(ground_truth,classifications)\r\n",
    "fpr,tpr,_= sklearn.metrics.roc_curve(y_true,y_pred)\r\n",
    "plt.plot(fpr,tpr)\r\n",
    "print('AUC:',auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From-Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = True\r\n",
    "shuffle = True\r\n",
    "\r\n",
    "training_gen,validation_gen = utils.generator_transfer(1000,800,data_augmentation,shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.create_trans_model(1000,800)\r\n",
    "model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['binary_accuracy','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\r\n",
    "    training_gen,\r\n",
    "    epochs=25,\r\n",
    "    validation_data=validation_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('transfer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = utils.generator_transfer(1000,800,True,False)\r\n",
    "y_true = data[1].classes\r\n",
    "y_pred = model.predict(data[1],data[1].samples//12+1)\r\n",
    "predictions_image = []\r\n",
    "for i in y_pred:\r\n",
    "    if i[0] > 0.5:\r\n",
    "        predictions_image.append(1)\r\n",
    "    else:\r\n",
    "        predictions_image.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sklearn.metris.confusion_matrix(y_true,predictions_image)\r\n",
    "sens = c[1][1]/(c[1][1]+c[1][0])\r\n",
    "spec = c[0][0]/(c[0][0]+c[0][1])\r\n",
    "print(c)\r\n",
    "print('Sensitivity:',sens)\r\n",
    "print('Specificity:',spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = sklearn.metrics.roc_auc_score(ground_truth,classifications)\r\n",
    "fpr,tpr,_= sklearn.metrics.roc_curve(y_true,y_pred)\r\n",
    "plt.plot(fpr,tpr)\r\n",
    "print('AUC:',auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('tensorflow': conda)",
   "name": "python37964bittensorflowconda44bf35c3046e4bc58c11f71047e9bd8d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "429db445d30bdc71cb8ecc91188709a24b250e6582e4f5179e4164d5371f1d5c"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}